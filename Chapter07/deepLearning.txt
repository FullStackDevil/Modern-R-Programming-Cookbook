Although deep learning approaches have had tremendous success in image, video and audio processing, computer vision, and speech recognition, their applications to three-dimensional (3D) biomolecular structural data sets have been hindered by the geometric and biological complexity. To address this problem we introduce the element-specific persistent homology (ESPH) method. ESPH represents 3D complex geometry by one-dimensional (1D) topological invariants and retains important biological information via a multichannel image-like representation. This representation reveals hidden structure-function relationships in biomolecules. We further integrate ESPH and deep convolutional neural networks to construct a multichannel topological neural network (TopologyNet) for the predictions of protein-ligand binding affinities and protein stability changes upon mutation. To overcome the deep learning limitations from small and noisy training sets, we propose a multi-task multichannel topological convolutional neural network (MM-TCNN). We demonstrate that TopologyNet outperforms the latest methods in the prediction of protein-ligand binding affinities, mutation induced globular protein folding free energy changes, and mutation induced membrane protein folding free energy changes.AVAILABILITY: weilab.math.msu.edu/TDL/.
Neonatal period represents first 28 days of life, which is the most vulnerable time for a child's survival especially for the preterm babies. High neonatal mortality is a prominent and persistent problem across the globe. Non-availability of trained staff and infrastructure are the major recognized hurdles in the quality care of these neonates. Hourly progress growth charts and reports are still maintained manually by nurses along with continuous calculation of drug dosage and nutrition as per the changing weight of the baby. iNICU (integrated Neonatology Intensive Care Unit) leverages Beaglebone and Intel Edison based IoT integration with biomedical devices in NICU i.e. monitor, ventilator and blood gas machine. iNICU is hosted on IBM Softlayer based cloud computing infrastructure and map NICU workflow in Java based responsive web application to provide translational research informatics support to the clinicians. iNICU captures real time vital parameters i.e. respiration rate, heart rate, lab data and PACS amounting for millions of data points per day per child. Stream of data is sent to Apache Kafka layer which stores the same in Apache Cassandra NoSQL. iNICU also captures clinical data like feed intake, urine output, and daily assessment of child in PostgreSQL database. It acts as first Big Data hub (of both structured and unstructured data) of neonates across India offering temporal (longitudinal) data of their stay in NICU and allow clinicians in evaluating efficacy of their interventions. iNICU leverages drools based clinical rule based engine and deep learning based big data analytical model coded in R and PMML. iNICU solution aims to improve care time, fills skill gap, enable remote monitoring of neonates in rural regions, assists in identifying the early onset of disease, and reduction in neonatal mortality.
Institutions have developed diverse approaches that vary in effectiveness and cost to improve student performance in introductory science, technology, engineering, and mathematics courses. We developed a low-cost, graduate student-led, metacognition-based study skills course taught in conjunction with the introductory biology series at Miami University. Our approach aimed to improve performance for underachieving students by combining an existing framework for the process of learning (the study cycle) with concrete tools (outlines and concept maps) that have been shown to encourage deep understanding. To assess the effectiveness of our efforts, we asked 1) how effective our voluntary recruitment model was at enrolling the target cohort, 2) how the course impacted performance on lecture exams, 3) how the course impacted study habits and techniques, and 4) whether there are particular study habits or techniques that are associated with large improvements on exam scores. Voluntary recruitment attracted only 11-17% of our target cohort. While focal students improved on lecture exams relative to their peers who did not enroll, gains were relatively modest, and not all students improved. Further, although students across both semesters of our study reported improved study habits (based on pre and post surveys) and on outlines and concept maps (based on retrospectively scored assignments), gains were more dramatic in the Fall semester. Multivariate models revealed that, while changes in study habits and in the quality of outlines and concept maps were weakly associated with change in performance on lecture exams, relationships were only significant in the Fall semester and were sometimes counterintuitive. Although benefits of the course were offset somewhat by the inefficiency of voluntary recruitment, we demonstrate the effectiveness our course, which is inexpensive to implement and has advantage of providing pedagogical experience to future educators.
Accurately annotating biological functions of proteins is one of the key tasks in the postgenome era. Many machine learning based methods have been applied to predict functional annotations of proteins, but this task is rarely solved by deep learning techniques. Deep learning techniques recently have been successfully applied to a wide range of problems, such as video, images, and nature language processing. Inspired by these successful applications, we investigate deep restricted Boltzmann machines (DRBM), a representative deep learning technique, to predict the missing functional annotations of partially annotated proteins. Experimental results on Homo sapiens, Saccharomyces cerevisiae, Mus musculus, and Drosophila show that DRBM achieves better performance than other related methods across different evaluation metrics, and it also runs faster than these comparing methods.
General anesthesia (GA) is a reversible drug-induced state of altered arousal required for more than 60,000 surgical procedures each day in the United States alone. Sedation and unconsciousness under GA are associated with stereotyped electrophysiological oscillations that are thought to reflect profound disruptions of activity in neuronal circuits that mediate awareness and cognition. Computational models make specific predictions about the role of the cortex and thalamus in these oscillations. In this paper, we provide in vivo evidence in rats that alpha oscillations (10-15 Hz) induced by the commonly used anesthetic drug propofol are synchronized between the thalamus and the medial prefrontal cortex. We also show that at deep levels of unconsciousness where movement ceases, coherent thalamocortical delta oscillations (1-5 Hz) develop, distinct from concurrent slow oscillations (0.1-1 Hz). The structure of these oscillations in both cortex and thalamus closely parallel those observed in the human electroencephalogram during propofol-induced unconsciousness. During emergence from GA, this synchronized activity dissipates in a sequence different from that observed during loss of consciousness. A possible explanation is that recovery from anesthesia-induced unconsciousness follows a &quot;boot-up&quot; sequence actively driven by ascending arousal centers. The involvement of medial prefrontal cortex suggests that when these oscillations (alpha, delta, slow) are observed in humans, self-awareness and internal consciousness would be impaired if not abolished. These studies advance our understanding of anesthesia-induced unconsciousness and altered arousal and further establish principled neurophysiological markers of these states.
OBJECTIVE: To evaluate associations between the Functional Movement Screen (FMS), Star Excursion Balance Test (SEBT), and Balance Error Scoring System (BESS) scores.DESIGN: Correlational.SETTING: College athletic training facilities.PARTICIPANTS: Fifty-two intercollegiate athletes (men = 36 and women = 16) representing 8 sports and cleared for unrestricted sport participation.INTERVENTIONS: Participants completed the FMS, SEBT, and BESS, in random order, during 1 testing session. Testing order was randomized to control for fatigue and learning effects.MAIN OUTCOME MEASURES: Composite and item scores for the FMS, SEBT, and BESS.RESULTS: A fair, negative correlation was found between FMS asymmetry and SEBT composite (r = -0.31, P = 0.03) scores. Fair, positive correlations were reported for FMS rotary stability task and SEBT anterior (r = 0.37-0.41, P = 0.007) and posteromedial (r = 0.31, P = 0.03) reaches. Fair, negative correlations were reported for FMS deep squat and BESS single-leg firm (r = -0.33, P = 0.02), double-leg foam (r = -0.34, P = 0.02) and tandem foam (r = -0.40, P = 0.003), FMS inline lunge and BESS single-leg firm (r = -0.39, P = 0.004), FMS trunk stability pushup and tandem foam (r = -0.31, P = 0.025), and FMS composite and BESS single-leg firm (r = -0.37, P = 0.007). Little-to-no correlations were reported for remaining comparisons.CONCLUSIONS: Results indicate that each instrument provides distinct information about function, with only small areas of overlap. Associations between the FMS asymmetry score and SEBT composite score may indicate a relationship between movement asymmetry and postural stability. Associations between the FMS deep squat and BESS foam tasks may be related to underlying neuromuscular control factors.
Broad Learning System (BLS) that aims to offer an alternative way of learning in deep structure is proposed in this paper. Deep structure and learning suffer from a time-consuming training process because of a large number of connecting parameters in filters and layers. Moreover, it encounters a complete retraining process if the structure is not sufficient to model the system. The BLS is established in the form of a flat network, where the original inputs are transferred and placed as &quot;mapped features&quot; in feature nodes and the structure is expanded in wide sense in the &quot;enhancement nodes.&quot; The incremental learning algorithms are developed for fast remodeling in broad expansion without a retraining process if the network deems to be expanded. Two incremental learning algorithms are given for both the increment of the feature nodes (or filters in deep structure) and the increment of the enhancement nodes. The designed model and algorithms are very versatile for selecting a model rapidly. In addition, another incremental learning is developed for a system that has been modeled encounters a new incoming input. Specifically, the system can be remodeled in an incremental way without the entire retraining from the beginning. Satisfactory result for model reduction using singular value decomposition is conducted to simplify the final structure. Compared with existing deep neural networks, experimental results on the Modified National Institute of Standards and Technology database and NYU NORB object recognition dataset benchmark data demonstrate the effectiveness of the proposed BLS.
OBJECTIVE: Acute coronary syndrome (ACS), as a common and severe cardiovascular disease, is a leading cause of death and the principal cause of serious long-term disability globally. Clinical risk prediction of ACS is important for early intervention and treatment. Existing ACS risk scoring models are based mainly on a small set of hand-picked risk factors and often dichotomize predictive variables to simplify the score calculation [1-3].METHODS: This study develops a regularized stacked denoising auto-encoder (SDAE) model to stratify clinical risks of ACS patients from a large volume of electronic health records (EHR). To capture characteristics of patients at similar risk levels, and preserve the discriminating information across different risk levels, two constraints are added on SDAE to make the reconstructed feature representations contain more risk information of patients, which contribute to a better clinical risk prediction result.RESULTS: We validate our approach on a real clinical dataset consisting of 3,464 ACS patient samples. The performance of our approach for predicting ACS risk remains robust and reaches 0.868 and 0.73 in terms of both AUC and Accuracy, respectively.CONCLUSIONS: The obtained results show that the proposed approach achieves a competitive performance compared to state-of-the-art models in dealing with the clinical risk prediction problem. In addition, our approach can extract informative risk factors of ACS via a reconstructive learning strategy. Some of these extracted risk factors are not only consistent with existing medical domain knowledge, but also contain suggestive hypotheses that could be validated by further investigations in the medical domain.
BACKGROUND: We report a study of machine learning applied to the phenotyping of psychiatric diagnosis for research recruitment in youth depression, conducted with 861 labelled electronic medical records (EMRs) documents. A model was built that could accurately identify individuals who were suitable candidates for a study on youth depression.OBJECTIVE: Our objective was a model to identify individuals who meet inclusion criteria as well as unsuitable patients who would require exclusion.METHODS: Our methods included applying a system that coded the EMR documents by removing personally identifying information, using two psychiatrists who labelled a set of EMR documents (from which the 861 came), using a brute force search and training a deep neural network for this task.FINDINGS: According to a cross-validation evaluation, we describe a model that had a specificity of 97% and a sensitivity of 45% and a second model with a specificity of 53% and a sensitivity of 89%. We combined these two models into a third one (sensitivity 93.5%; specificity 68%; positive predictive value (precision) 77%) to generate a list of most suitable candidates in support of research recruitment.CONCLUSION: Our efforts are meant to demonstrate the potential for this type of approach for patient recruitment purposes but it should be noted that a larger sample size is required to build a truly reliable recommendation system.CLINICAL IMPLICATIONS: Future efforts will employ alternate neural network algorithms available and other machine learning methods.
Plant phenomics has received increasing interest in recent years in an attempt to bridge the genotype-to-phenotype knowledge gap. There is a need for expanded high-throughput phenotyping capabilities to keep up with an increasing amount of data from high-dimensional imaging sensors and the desire to measure more complex phenotypic traits (Knecht et al., 2016). In this paper, we introduce an open-source deep learning tool called Deep Plant Phenomics. This tool provides pre-trained neural networks for several common plant phenotyping tasks, as well as an easy platform that can be used by plant scientists to train models for their own phenotyping applications. We report performance results on three plant phenotyping benchmarks from the literature, including state of the art performance on leaf counting, as well as the first published results for the mutant classification and age regression tasks for Arabidopsis thaliana.
